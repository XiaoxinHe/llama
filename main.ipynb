{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "\n",
    "# nodeidx2asin = pd.read_csv(\n",
    "#     'dataset/ogbn_products/mapping/nodeidx2asin.csv.gz', compression='gzip')\n",
    "# nodeidx2asin.set_index('asin', inplace=True)\n",
    "\n",
    "\n",
    "# responses = glob.glob('output/ogbn-products/*.json')\n",
    "\n",
    "# for res in responses:\n",
    "#     asin = res.split('/')[-1].split('.json')[0]\n",
    "#     nodeidx = nodeidx2asin.loc[asin]['node idx']\n",
    "#     fn = f'output/ogbn-products/{nodeidx}.json'\n",
    "#     os.rename(res, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "dataset = PygNodePropPredDataset(\n",
    "    name='ogbn-products', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "\n",
    "responses = glob.glob('/home/xiaoxin/llama/output/ogbn-products/*.json')\n",
    "print(len(responses))\n",
    "\n",
    "# classes = labelidx2productcategory['product category'].str.lower().tolist()\n",
    "classes = ['home & kitchen', 'health & personal care', 'beauty', 'sports & outdoors', 'books', 'patio, lawn & garden', 'toys & games', 'cds & vinyl', 'cell phones & accessories', 'grocery & gourmet food', 'arts, crafts & sewing', 'clothing, shoes & jewelry', 'electronics', 'movies & tv', 'software', 'video games', 'automotive', 'pet supplies', 'office products', 'industrial & scientific', 'musical instruments', 'tools & home improvement',\n",
    "           'magazine subscriptions', 'baby products', 'nan', 'appliances', 'kitchen & dining', 'collectibles & fine art', 'all beauty', 'luxury beauty', 'amazon fashion', 'computers', 'all electronics', 'purchase circles', 'mp3 players & accessories', 'gift cards', 'office & school supplies', 'home improvement', 'camera & photo', 'gps & navigation', 'digital music', 'car electronics', 'baby', 'kindle store', 'kindle apps', 'furniture & decor']\n",
    "classes\n",
    "classes = [i if i is not np.nan else 'nan' for i in classes]\n",
    "classes_regex = '(' + '|'.join(classes) + ')'\n",
    "class_map = {x: i for i, x in enumerate(classes)}\n",
    "\n",
    "\n",
    "pred = []\n",
    "limit = len(responses)\n",
    "for fn in responses:\n",
    "    response = json.load(open(fn, \"r\"))\n",
    "    answer = response['generation']['content'].lower()\n",
    "\n",
    "    matches = re.findall(classes_regex, answer.strip())\n",
    "\n",
    "    mapped = [class_map[m] for m in matches]\n",
    "\n",
    "    if len(mapped) == 0:\n",
    "        # print(\"EMPTY: \", answer)\n",
    "        mapped = [1]\n",
    "\n",
    "    pred.append(mapped)\n",
    "\n",
    "responses_nodeidx = [int(res.split('/')[-1].split('.json')[0])\n",
    "                     for res in responses]\n",
    "labels = data.y[responses_nodeidx]\n",
    "\n",
    "accs = []\n",
    "for k in range(1, 6):\n",
    "    acc = np.mean([labels[row].item() in pred[row][:k]\n",
    "                  for row in range(limit)])\n",
    "    accs.append(acc)\n",
    "print('accs: ', accs)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples: 2242\n",
      "accs:  [0.4023193577163247, 0.5695807314897413, 0.6271186440677966, 0.6578947368421053, 0.6623550401427297]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from utils.load_arxiv import get_raw_text_arxiv\n",
    "\n",
    "data, text = get_raw_text_arxiv(use_text=False)\n",
    "\n",
    "\n",
    "label2text = pd.read_csv(\n",
    "    \"./dataset/{}/label2text.csv\".format('ogbn_arxiv'))\n",
    "options = label2text['arxiv category'].str.slice(start=9).str.upper().tolist()\n",
    "pred = []\n",
    "\n",
    "responses = glob.glob('output/ogbn-arxiv/*.json')\n",
    "answers = []\n",
    "idx_to_query = []\n",
    "for res in responses:\n",
    "    idx_to_query.append(int(res.split('/')[-1].split('.json')[0]))\n",
    "    response = json.load(open(res))\n",
    "    answer = response['generation']['content']\n",
    "    matches = re.findall(r\"cs\\.[A-Z]{2}\", answer.strip())\n",
    "    topk = [x[3:] for x in list(dict.fromkeys(matches))[:5]]\n",
    "    pred.append([options.index(c) for c in topk if c in options])\n",
    "\n",
    "\n",
    "# compute top-k accuracy for k=1,...5\n",
    "labels = data.y[idx_to_query]\n",
    "accs = []\n",
    "for k in range(1, 6):\n",
    "    acc = np.mean([labels[row].item() in pred[row][:k]\n",
    "                  for row in range(len(idx_to_query))])\n",
    "    accs.append(acc)\n",
    "\n",
    "print(f\"# of samples: {len(idx_to_query)}\")\n",
    "print('accs: ', accs)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
